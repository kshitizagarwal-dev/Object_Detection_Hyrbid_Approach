{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXVQ8mNU6BI7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvVaAkjtrltb",
        "outputId": "b16aa109-95b7-474a-816f-dd376230f0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip '/content/drive/MyDrive/updated_COCO_Dataset (1).zip' -d '/content'"
      ],
      "metadata": {
        "id": "85L55UvqKgSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1575b8a9-3f3d-40c2-80ec-9f1131bbfc87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/updated_COCO_Dataset (1).zip\n",
            "replace /content/content/dataset_1/COCO_Dataset/train/annotations/instances_default.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "! pip install supervision\n",
        "! pip install openai==1.0.0\n",
        "! pip install instructor"
      ],
      "metadata": {
        "id": "dAuQU6VwVq98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10081723-0287-4293-a8c0-20caee1d7154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting pyyaml==5.1\n",
            "  Using cached PyYAML-5.1.tar.gz (274 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "fatal: destination path 'detectron2' already exists and is not an empty directory.\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (24.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs>=0.1.8) (6.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7) (2.8.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.1) (4.9.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (4.2.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.11.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.9.0.80)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n",
            "Collecting openai==1.0.0\n",
            "  Using cached openai-1.0.0-py3-none-any.whl (154 kB)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.0.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.0.0) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.0.0) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.0.0) (2.7.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.0.0) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.0.0) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.0.0) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.0.0) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.0.0) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.0.0) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.0.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.0.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.0.0) (2.18.2)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.28.1\n",
            "    Uninstalling openai-1.28.1:\n",
            "      Successfully uninstalled openai-1.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "instructor 1.2.6 requires openai<2.0.0,>=1.1.0, but you have openai 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-1.0.0\n",
            "Requirement already satisfied: instructor in /usr/local/lib/python3.10/dist-packages (1.2.6)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor) (3.9.5)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor) (0.16)\n",
            "Collecting openai<2.0.0,>=1.1.0 (from instructor)\n",
            "  Using cached openai-1.28.1-py3-none-any.whl (320 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (2.7.1)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (2.18.2)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor) (8.3.0)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (0.9.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (4.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->instructor) (0.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor) (8.1.7)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.1.0->instructor) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.1.0->instructor) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor) (0.1.2)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.0.0\n",
            "    Uninstalling openai-1.0.0:\n",
            "      Successfully uninstalled openai-1.0.0\n",
            "Successfully installed openai-1.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAwyflKh-TQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the libraries\n",
        "\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "import shutil\n",
        "\n",
        "from typing import Tuple, List\n",
        "import supervision as sv\n",
        "import torch"
      ],
      "metadata": {
        "id": "XF8A4FMFSVzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fn to annotate the bounding boxes on the image\n",
        "def annotate1(image_source: np.ndarray, boxes: np.ndarray,  phrases: List[str],logits: List = None) -> np.ndarray:\n",
        "    h, w, _ = image_source.shape\n",
        "\n",
        "    # boxes = boxes * torch.Tensor([w, h, w, h])\n",
        "\n",
        "    # xyxy = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").numpy()\n",
        "\n",
        "    detections = sv.Detections(boxes)\n",
        "    # print(phrases)\n",
        "\n",
        "    if logits == None:\n",
        "      labels = phrases\n",
        "    else:\n",
        "\n",
        "        labels = [\n",
        "            f\"{phrase} {logit:.2f}\"\n",
        "            for phrase, logit\n",
        "            in zip(phrases, logits)\n",
        "        ]\n",
        "\n",
        "    box_annotator = sv.BoxAnnotator()\n",
        "    annotated_frame = cv2.cvtColor(image_source, cv2.COLOR_RGB2BGR)\n",
        "    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
        "    return annotated_frame"
      ],
      "metadata": {
        "id": "i_xnrhg7-D3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# providing dataset and registering it\n",
        "# registering the data set\n",
        "train_json_path = '/content/content/dataset_1/COCO_Dataset/train/annotationsinstances_default.json'\n",
        "valid_json_path = '/content/content/dataset_1/COCO_Dataset/valid/annotationsinstances_default.json'\n",
        "\n",
        "register_coco_instances(\"my_dataset_train\", {}, train_json_path, \"/content/content/dataset_1/COCO_Dataset/train/images\")\n",
        "register_coco_instances(\"my_dataset_val\", {}, valid_json_path, \"/content/content/dataset_1/COCO_Dataset/train/images\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1hNCFdCsSrYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "c95e505a-c5a9-4bb8-ecb6-9b10348d4bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Dataset 'my_dataset_train' is already registered!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-55c3c9481696>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_json_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/content/dataset_1/COCO_Dataset/valid/annotationsinstances_default.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_dataset_train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_json_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/content/dataset_1/COCO_Dataset/train/images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_dataset_val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_json_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/content/dataset_1/COCO_Dataset/train/images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[1;32m     36\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You must register a function with `DatasetCatalog.register`!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is already registered!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Dataset 'my_dataset_train' is already registered!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the metadata for the dataset\n",
        "MetadataCatalog.get(\"my_dataset_train\").set(thing_classes=[\"Rust\"])\n",
        "MetadataCatalog.get(\"my_dataset_val\").set(thing_classes=[\"Rust\"])\n",
        "metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "metadata_val = MetadataCatalog.get(\"my_dataset_val\")\n",
        "print(metadata)\n",
        "print(metadata_val)\n",
        "\n",
        "# creating and setting the configuration parameter for model\n",
        "cfg = get_cfg()\n",
        "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
        "# cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # Increase this number based on your GPU memory\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 500\n",
        "cfg.SOLVER.STEPS = []  # No LR steps, you can add steps if you want LR decay\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 16\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "\n",
        "# model loading\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/rust/model_final.pth'  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.60   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hh4fbUhT0vt",
        "outputId": "967b33da-7e13-4627-cd71-cfe89bc3b031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata(name='my_dataset_train', json_file='/content/content/dataset_1/COCO_Dataset/train/annotationsinstances_default.json', image_root='/content/content/dataset_1/COCO_Dataset/train/images', evaluator_type='coco', thing_classes=['Rust'])\n",
            "Metadata(name='my_dataset_val', json_file='/content/content/dataset_1/COCO_Dataset/valid/annotationsinstances_default.json', image_root='/content/content/dataset_1/COCO_Dataset/train/images', evaluator_type='coco', thing_classes=['Rust'])\n",
            "[05/13 09:16:19 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/rust/model_final.pth ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Identifying the rust using trained model"
      ],
      "metadata": {
        "id": "OCgL1cPX2wav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rust Identfication to identify the rust , using our model here\n",
        "def rust_identification(im):\n",
        "      '''\n",
        "      Return:\n",
        "      bounding boxes\n",
        "      im :size 1024 x 1024\n",
        "      '''\n",
        "      try:\n",
        "        shutil.rmtree('/content/images')\n",
        "        os.mkdir('/content/images')\n",
        "      except:\n",
        "          os.mkdir('/content/images')\n",
        "\n",
        "      # im = cv2.imread('/content/drive/MyDrive/rust/Gemini_Generated_Image_7x4h7d7x4h7d7x4h.jpg')\n",
        "      # im = cv2.resize(im, (1024, 1024))\n",
        "      # print(im)\n",
        "      outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "      v = Visualizer(im[:, :, ::-1],\n",
        "                      metadata=metadata,\n",
        "                      scale=0.5,\n",
        "                      instance_mode=ColorMode.IMAGE   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "      )\n",
        "      out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "      # cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "      # Assuming 'instances' contains the Instances object returned by model inference\n",
        "      # Move the tensors from GPU to CPU\n",
        "      instances = outputs[\"instances\"]\n",
        "      pred_boxes = instances.pred_boxes.tensor.cpu().numpy()\n",
        "      scores = instances.scores.cpu().numpy()\n",
        "      pred_classes = instances.pred_classes.cpu().numpy()\n",
        "      bounding_boxes = []\n",
        "      for i, bbox in enumerate(pred_boxes):\n",
        "          x1, y1, x2, y2 = bbox\n",
        "          bounding_boxes.append([x1, y1, x2, y2])\n",
        "      print(bounding_boxes)\n",
        "      return bounding_boxes, im\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#####################For minimizing the overlapping bounding boxes###########################################################\n",
        "\n",
        "\n",
        "# Function to calculate the area of intersection between two rectangles\n",
        "def intersection_area(rect1, rect2):\n",
        "    x_overlap = max(0, min(rect1[2], rect2[2]) - max(rect1[0], rect2[0]))\n",
        "    y_overlap = max(0, min(rect1[3], rect2[3]) - max(rect1[1], rect2[1]))\n",
        "    return x_overlap * y_overlap\n",
        "\n",
        "# Function to fill overlapping areas with black color\n",
        "def fill_overlapping_areas(image, rectangles):\n",
        "    mask = np.zeros_like(image)\n",
        "    for i, rect1 in enumerate(rectangles):\n",
        "        for j, rect2 in enumerate(rectangles):\n",
        "            if i != j:\n",
        "                area = intersection_area(rect1, rect2)\n",
        "                if area > 0:\n",
        "                    overlap_x1 = max(rect1[0], rect2[0])\n",
        "                    overlap_y1 = max(rect1[1], rect2[1])\n",
        "                    overlap_x2 = min(rect1[2], rect2[2])\n",
        "                    overlap_y2 = min(rect1[3], rect2[3])\n",
        "                    mask[int(overlap_y1):int(overlap_y2), int(overlap_x1):int(overlap_x2)] = 255\n",
        "    image[mask == 255] = 0\n",
        "    return image\n",
        "\n",
        "# Function to calculate the percentage of black color within a bounding box\n",
        "def black_area_percentage(image, rectangle):\n",
        "    total_pixels = (rectangle[2] - rectangle[0]) * (rectangle[3] - rectangle[1])\n",
        "    black_pixels = np.count_nonzero(image[int(rectangle[1]):int(rectangle[3]), int(rectangle[0]):int(rectangle[2])] == 0)\n",
        "    return (black_pixels / total_pixels) * 100\n",
        "\n",
        "\n",
        "# Based on the threshold value i.e. the percentage of overlapping area, we are removing the bounding box\n",
        "def remove_box(bounding_boxes, image, threshold):\n",
        "    max_black_area = -1\n",
        "    index_to_remove = -1\n",
        "    for i, box in enumerate(bounding_boxes):\n",
        "        percentage_black = black_area_percentage(image, box)\n",
        "        if percentage_black > threshold:\n",
        "            area = (box[2] - box[0]) * (box[3] - box[1])\n",
        "            if area > max_black_area:\n",
        "                max_black_area = area\n",
        "                index_to_remove = i\n",
        "    if index_to_remove != -1:\n",
        "        del bounding_boxes[index_to_remove]\n",
        "    return bounding_boxes\n",
        "\n",
        "\n",
        "\n",
        "#bounding_boxes = pred_boxes\n",
        "# Iteratively remove bounding boxes with black color above 90 percent and highest area of black color\n",
        "def preprocess_bbox(bounding_boxes):\n",
        "  iteration = 1\n",
        "  max_iterations = 10\n",
        "\n",
        "  # Iteratively remove bounding boxes with black color above 90 percent and highest area of black color\n",
        "  iteration = 1\n",
        "  max_iterations = 10\n",
        "\n",
        "  while iteration <= max_iterations:\n",
        "\n",
        "      image_after_filling = np.ones((1024, 1024), dtype=np.uint8) * 255  # White background\n",
        "      image_after_filling = fill_overlapping_areas(image_after_filling, bounding_boxes)\n",
        "\n",
        "      # Calculate and display the percentage of black color for each bounding box\n",
        "      for i, box in enumerate(bounding_boxes):\n",
        "          percentage_black = black_area_percentage(image_after_filling, box)\n",
        "\n",
        "      # bounding_boxes = remove_box(bounding_boxes, image_after_filling)\n",
        "      bounding_boxes = remove_box(bounding_boxes, image_after_filling, threshold=90)\n",
        "\n",
        "      # Break the loop if there's only one bounding box left\n",
        "      if len(bounding_boxes) == 1:\n",
        "          break\n",
        "\n",
        "      iteration += 1\n",
        "  return bounding_boxes\n",
        "\n",
        "\n",
        "# Crop the bounding boxes from the original image\n",
        "def crop_bounding_box(image, bounding_box):\n",
        "    # Convert bounding box coordinates to integers\n",
        "\n",
        "    x1, y1, x2, y2 = map(int, bounding_box)\n",
        "\n",
        "    # Crop the region of interest (ROI) from the original image\n",
        "    cropped_image = image[y1:y2, x1:x2]\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Read the original image and cropping and save the image based on the bounding boxes\n",
        "# work as the main function for this block\n",
        "def saving_croppedImg(im):\n",
        "    # getting the bounding boxes and read image by using the model\n",
        "    bounding_boxes, original_image = rust_identification(im)\n",
        "    print(len(bounding_boxes))\n",
        "    #Remove the overlapping bounding boxes\n",
        "    bounding_boxes = preprocess_bbox(bounding_boxes)\n",
        "    print(len(bounding_boxes))\n",
        "    print(\"Remaining Bounding Box Coordinates:\")\n",
        "    for i, box in enumerate(bounding_boxes):\n",
        "        print(f\"Bounding Box {i+1}: {box}\")\n",
        "        cropped_part = crop_bounding_box(original_image, box)\n",
        "        # cv2_imshow(cropped_part)\n",
        "        cv2.imwrite(f\"images/cropped_image_{i}.jpg\", cropped_part)\n",
        "    return bounding_boxes\n",
        "\n",
        "\n",
        "# result = []\n",
        "# print(len(bounding_boxes))\n",
        "# for i, bbox in enumerate(pred_boxes):\n",
        "#     x1, y1, x2, y2 = bbox\n",
        "\n"
      ],
      "metadata": {
        "id": "HGq1WHwFS3er"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GJfmgiRDreJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cropping the images**\n"
      ],
      "metadata": {
        "id": "s4nq6r8OE_DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPENAI**"
      ],
      "metadata": {
        "id": "rTLH_JIuEJda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =  \"<your key>\"\n"
      ],
      "metadata": {
        "id": "TKBFDh1A2S4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import instructor\n",
        "from instructor import Mode\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "from pprint import pprint\n",
        "import base64\n",
        "# from dotenv import load_dotenv\n",
        "\n",
        "# load_dotenv()\n",
        "\n",
        "client = instructor.patch(OpenAI(), mode=Mode.MD_JSON)\n",
        "# reading the image and encoding it into encode it into base64\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "class ObjectDetection(BaseModel):\n",
        "    # \"\"\"\n",
        "    # You are an object detection expert.\n",
        "    # From the given list ,['High Rust', 'Low Rust', 'Medium Rust'] .\n",
        "    # First identify if the object exist in the image. If object exist then provide the bounding box of the object and object name.\n",
        "    # \"\"\"\n",
        "    x: int  = Field(description=\"x coordinate of detected object\", default=0)\n",
        "    y: int = Field(description=\"y coordinate of detected object\", default=0)\n",
        "    object_found_details: str = Field(description=\"Details of detected object.\", default=\"\")\n",
        "    image_description: str = Field(descripion=\"Description of image.\", default=\"\")\n",
        "\n",
        "#fn for calling gpt 4 for an image\n",
        "def ask_gpt4_vision(system_instrutions, question, image_path):\n",
        "    base64_image = encode_image(image_path)\n",
        "\n",
        "    detected = client.chat.completions.create(\n",
        "        response_model=ObjectDetection,\n",
        "        model=\"gpt-4-turbo\",\n",
        "        max_tokens=200,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_instrutions\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": question},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    return {\"x\": detected.x, \"y\": detected.y, \"object_found_details\": detected.object_found_details, \"image_description\": detected.image_description}\n",
        "\n",
        "\n",
        "\n",
        "# question = \"Can you tell me type of rust on the image.\"\n",
        "#coordinates = ask_gpt4_vision(system_instructions, question, image_path)\n",
        "# to call the gpt 4 on the cropped images\n",
        "#for call ing gpt4 on number of images present in the folder\n",
        "def gpt4_vision_call(resized_path, system_instructions, questions):\n",
        "  file_list = os.listdir(resized_path)\n",
        "  file_list.sort()\n",
        "  detected_labels = []\n",
        "  # print(file_list)\n",
        "# reading the file one by one in folder\n",
        "  for files in file_list:\n",
        "    # checking for the extension of the file\n",
        "        if files.endswith(\".jpg\") or files.endswith(\".png\"):\n",
        "          image_path = os.path.join(resized_path, files)\n",
        "          print(image_path)\n",
        "          coordinates = ask_gpt4_vision(system_instructions, questions, image_path)\n",
        "          print(coordinates['object_found_details'], \"-->\", coordinates['image_description'])\n",
        "          detected_labels.append(coordinates['object_found_details'])\n",
        "  return detected_labels\n",
        "\n",
        "\n",
        "# for calling the above two functions with prompt\n",
        "def call_gpt(im, bounding_boxes = None):\n",
        "\n",
        "    system_instructions1 =   \"\"\"\n",
        "    As an expert in object detection, you specialize in pinpointing specific elements within images.\n",
        "    Given your expertise, you can efficiently analyze the provided image for any items listed, such as ['High Rust', 'Low Rust', 'Medium Rust', 'No Rust'].\n",
        "    Rust is formed due to the corrosion on metal surface of electric pole, and it is of red-brownish color. It destroys the metal surface.\n",
        "    Below is the deifinition of different types of rust:\n",
        "    Once identified, you will accurately mark their presence by providing both the bounding box coordinates and the name of the detected object.\n",
        "    You have to identify all the different areas of rust\n",
        "    It is crucial to exclude any  information from the image to adhere to privacy and data protection standards.\n",
        "    Output should only contain the type of rust no description is needed.\n",
        "    \"\"\"\n",
        "    question = \"Can you tell me type of rust on the image.\"\n",
        "\n",
        "    labels = gpt4_vision_call(resized_path = '/content/images',system_instructions =  system_instructions1, questions = question)\n",
        "\n",
        "  # if bounding boxes are present.\n",
        "    if bounding_boxes !=None:\n",
        "      bounding_boxes_array = np.array(bounding_boxes)\n",
        "      annotated_frame_1 = annotate1(image_source=im, boxes=bounding_boxes_array,  phrases=labels)\n",
        "      annotated_frame = annotated_frame_1[...,::-1]\n",
        "      rgb_image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
        "      rgb_image1 = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
        "      cv2.imwrite('result.jpg', rgb_image1)\n",
        "\n",
        "      return rgb_image1\n",
        "    else:\n",
        "      print(\"Image has no visible sign of rust\")\n",
        "      return im\n",
        "\n",
        "# try:\n",
        "#   os.mkdir('/content/output')\n",
        "# except:\n",
        "#   pass\n",
        "\n",
        "# cv2.imwrite('/content/output/result.jpg', annotated_frame)\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.imshow(rgb_image)\n",
        "# plt.axis('on')  # Hide axis\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "RDbaLNkf2Tfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the image and annotating it\n",
        "im = cv2.imread('/content/drive/MyDrive/rust/Gemini_Generated_Image_7x4h7d7x4h7d7x4h.jpg')\n",
        "#im = cv2.imread('/content/drive/MyDrive/rust/Gemini_Generated_Image_6mhtol6mhtol6mht.jpg')# no rust\n",
        "im = cv2.resize(im, (1024, 1024))\n",
        "bounding_boxes = saving_croppedImg(im)\n",
        "if bounding_boxes == []:\n",
        "  image_annotated = call_gpt(im)\n",
        "else:\n",
        "  image_annotated = call_gpt(im, bounding_boxes)\n",
        "# image_annotated, bounding_boxes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi19JDr1t5We",
        "outputId": "e0bdfdda-cb21-461d-cfd5-f7ea9a5af861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[90.058395, 160.0482, 633.0455, 1024.0], [98.75448, 151.80304, 379.91147, 850.0121], [301.26562, 219.20546, 623.15497, 947.07825], [91.48371, 495.94437, 170.08847, 988.90985], [350.6838, 188.31682, 639.68085, 674.59204], [71.406685, 183.63828, 347.80167, 558.8877], [137.68114, 187.50072, 614.6715, 601.78973], [292.08713, 559.0202, 620.3451, 993.68005]]\n",
            "8\n",
            "4\n",
            "Remaining Bounding Box Coordinates:\n",
            "Bounding Box 1: [98.75448, 151.80304, 379.91147, 850.0121]\n",
            "Bounding Box 2: [91.48371, 495.94437, 170.08847, 988.90985]\n",
            "Bounding Box 3: [350.6838, 188.31682, 639.68085, 674.59204]\n",
            "Bounding Box 4: [292.08713, 559.0202, 620.3451, 993.68005]\n",
            "/content/images/cropped_image_0.jpg\n",
            "High Rust --> The image shows a metal surface with extensive corrosion displaying red-brownish rust, categorized as 'High Rust'.\n",
            "/content/images/cropped_image_1.jpg\n",
            "High Rust --> A vertical strip of metal with a significant presence of deep red-brownish rust concentrated in the middle, indicating a high level of corrosion.\n",
            "/content/images/cropped_image_2.jpg\n",
            "High Rust --> The image displays a metal surface with extensive red-brownish corrosion indicative of high rust.\n",
            "/content/images/cropped_image_3.jpg\n",
            "High Rust --> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfEs9VinosvB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}