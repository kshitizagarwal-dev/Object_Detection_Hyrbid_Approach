{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtU-t_2RQHEV"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWWkO706XBE5",
        "outputId": "af8bb286-1a13-4d3d-d9bf-8505aea56fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHUbk-ecQVFL",
        "outputId": "dfcb7a1a-5f7b-4720-93b1-478c89e82a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.2 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgKJO8OUZeH6"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6v8KQ-8xnGd"
      },
      "outputs": [],
      "source": [
        "# unzip the dataset\n",
        "!unzip /content/drive/MyDrive/detectron2_object_detection/RustCOCO.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j7693lk4Bk7Z",
        "outputId": "b0d2df06-39d5-4452-91c4-8ef8dcd137ba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zii3f4bMnQZv"
      },
      "outputs": [],
      "source": [
        "# to be used once model is trained supposed to run at the end\n",
        "!zip -r '/content/drive/MyDrive/Colab Notebooks/object detection/model' /content/output_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcyMYM10yBH4",
        "outputId": "e7d4b200-0f3e-47ce-9d2f-98846f89d46e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metadata(name='my_dataset_train', json_file='/content/RustCOCO/train_rust/annotations/instances_default.json', image_root='/content/RustCOCO/train_rust/images', evaluator_type='coco', thing_classes=['Rust', 'No Rust'])\n",
            "Metadata(name='my_dataset_val', json_file='/content/RustCOCO/valid_rust/annotations/instances_default.json', image_root='/content/RustCOCO/valid_rust/images', evaluator_type='coco', thing_classes=['Rust', 'No Rust'])\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "def load_dataset_from_json(json_file):\n",
        "    \"\"\"\n",
        "    Load dataset annotations from a JSON file in COCO format.\n",
        "\n",
        "    Args:\n",
        "        json_file (str): Path to the JSON file containing the annotations.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: List of dictionary objects where each dictionary corresponds to an image and its annotations.\n",
        "    \"\"\"\n",
        "    with open(json_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for img in data[\"images\"]:\n",
        "        record = {}\n",
        "        filename = img[\"file_name\"]\n",
        "        record[\"file_name\"] = filename  # Image file path\n",
        "        record[\"image_id\"] = img[\"id\"]  # Image ID\n",
        "        record[\"height\"] = img[\"height\"]  # Image height\n",
        "        record[\"width\"] = img[\"width\"]  # Image width\n",
        "\n",
        "        objs = []\n",
        "        for ann in data[\"annotations\"]:\n",
        "            if ann[\"image_id\"] == img[\"id\"]:\n",
        "                obj = {\n",
        "                    \"bbox\": ann[\"bbox\"],  # Bounding box coordinates\n",
        "                    \"bbox_mode\": BoxMode.XYWH_ABS,  # Bounding box mode (XYWH_ABS means [x, y, width, height])\n",
        "                    \"category_id\": ann[\"category_id\"],  # Category ID of the object\n",
        "                }\n",
        "                objs.append(obj)\n",
        "        record[\"annotations\"] = objs  # Annotations for the current image\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# Paths to the training and validation JSON annotation files\n",
        "train_json_path = '/content/RustCOCO/train_rust/annotations/instances_default.json'\n",
        "valid_json_path = '/content/RustCOCO/valid_rust/annotations/instances_default.json'\n",
        "\n",
        "# Register the dataset using COCO format\n",
        "# This function adds the dataset to the DatasetCatalog and MetadataCatalog\n",
        "register_coco_instances(\"my_dataset_train\", {}, train_json_path, \"/content/RustCOCO/train_rust/images\")\n",
        "register_coco_instances(\"my_dataset_val\", {}, valid_json_path, \"/content/RustCOCO/valid_rust/images\")\n",
        "\n",
        "# Set metadata for the datasets, including class names\n",
        "MetadataCatalog.get(\"my_dataset_train\").set(thing_classes=[\"Rust\", \"No Rust\"])\n",
        "MetadataCatalog.get(\"my_dataset_val\").set(thing_classes=[\"Rust\", \"No Rust\"])\n",
        "\n",
        "# Get the metadata\n",
        "metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "metadata_val = MetadataCatalog.get(\"my_dataset_val\")\n",
        "\n",
        "# Print metadata to verify\n",
        "print(metadata)\n",
        "print(metadata_val)\n",
        "\n",
        "# Now you can use \"my_dataset_train\" and \"my_dataset_val\" for training or evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t9ScuJwc41p"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import cv2\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from google.colab.patches import cv2_imshow  # Assuming you are using Google Colab\n",
        "\n",
        "# Load the dataset dictionaries for the validation dataset\n",
        "dataset_dicts = load_dataset_from_json(valid_json_path)\n",
        "\n",
        "# Randomly sample 3 images from the dataset for visualization\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    print(d['file_name'])  # Print the file name of the image being processed\n",
        "    img = cv2.imread('/content/RustCOCO/valid_rust/images/' + d[\"file_name\"])  # Read the image file\n",
        "    # Create a Visualizer object to visualize the image and annotations\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata_val, scale=0.5)  # img[:, :, ::-1] converts BGR to RGB\n",
        "    print(visualizer, d)  # Print the visualizer object and the dictionary for debugging purposes\n",
        "    vis = visualizer.draw_dataset_dict(d)  # Draw the annotations on the image\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])  # Display the image with annotations (converting RGB back to BGR for display)\n",
        "``\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URgxn67XtRNi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlu_JoC4dSWc",
        "outputId": "0b71f2a1-b75d-4385-aa72-72f62bcf8d2a",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/07 11:24:06 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[05/07 11:24:06 d2.data.datasets.coco]: Loaded 89 images in COCO format from /content/RustCOCO/train_rust/annotations/instances_default.json\n",
            "[05/07 11:24:06 d2.data.build]: Removed 0 images with no usable annotations. 89 images left.\n",
            "[05/07 11:24:06 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "|    Rust    | 199          |  No Rust   | 15           |\n",
            "|            |              |            |              |\n",
            "|   total    | 214          |            |              |\n",
            "[05/07 11:24:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[05/07 11:24:06 d2.data.build]: Using training sampler TrainingSampler\n",
            "[05/07 11:24:06 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[05/07 11:24:06 d2.data.common]: Serializing 89 elements to byte tensors and concatenating them all ...\n",
            "[05/07 11:24:06 d2.data.common]: Serialized dataset takes 0.03 MiB\n",
            "[05/07 11:24:06 d2.data.build]: Making batched data loader with batch_size=2\n",
            "[05/07 11:24:06 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_C4_3x/137849393/model_final_f97cb7.pkl ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_final_f97cb7.pkl: 136MB [00:00, 272MB/s]                           \n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/07 11:24:06 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/07 11:24:18 d2.utils.events]:  eta: 0:02:38  iter: 19  total_loss: 1.762  loss_cls: 0.708  loss_box_reg: 0.6754  loss_rpn_cls: 0.2387  loss_rpn_loc: 0.05045    time: 0.3408  last_time: 0.3160  data_time: 0.0212  last_data_time: 0.0012   lr: 9.7405e-06  max_mem: 1449M\n",
            "[05/07 11:24:29 d2.utils.events]:  eta: 0:02:39  iter: 39  total_loss: 1.955  loss_cls: 0.6494  loss_box_reg: 0.8956  loss_rpn_cls: 0.2577  loss_rpn_loc: 0.1216    time: 0.3640  last_time: 0.3451  data_time: 0.0153  last_data_time: 0.0148   lr: 1.9731e-05  max_mem: 1511M\n",
            "[05/07 11:24:37 d2.utils.events]:  eta: 0:02:33  iter: 59  total_loss: 1.559  loss_cls: 0.5606  loss_box_reg: 0.6841  loss_rpn_cls: 0.1721  loss_rpn_loc: 0.06343    time: 0.3753  last_time: 0.3559  data_time: 0.0123  last_data_time: 0.0132   lr: 2.972e-05  max_mem: 1511M\n",
            "[05/07 11:24:44 d2.utils.events]:  eta: 0:02:25  iter: 79  total_loss: 1.619  loss_cls: 0.5306  loss_box_reg: 0.8093  loss_rpn_cls: 0.1473  loss_rpn_loc: 0.05817    time: 0.3648  last_time: 0.3242  data_time: 0.0101  last_data_time: 0.0149   lr: 3.9711e-05  max_mem: 1511M\n",
            "[05/07 11:24:52 d2.utils.events]:  eta: 0:02:20  iter: 99  total_loss: 1.564  loss_cls: 0.4818  loss_box_reg: 0.839  loss_rpn_cls: 0.1578  loss_rpn_loc: 0.1228    time: 0.3740  last_time: 0.3731  data_time: 0.0153  last_data_time: 0.0060   lr: 4.9701e-05  max_mem: 1546M\n",
            "[05/07 11:24:59 d2.utils.events]:  eta: 0:02:14  iter: 119  total_loss: 1.489  loss_cls: 0.4141  loss_box_reg: 0.7222  loss_rpn_cls: 0.1516  loss_rpn_loc: 0.1042    time: 0.3712  last_time: 0.3462  data_time: 0.0120  last_data_time: 0.0176   lr: 5.9691e-05  max_mem: 1546M\n",
            "[05/07 11:25:08 d2.utils.events]:  eta: 0:02:07  iter: 139  total_loss: 1.475  loss_cls: 0.4405  loss_box_reg: 0.7634  loss_rpn_cls: 0.1759  loss_rpn_loc: 0.09996    time: 0.3765  last_time: 0.4909  data_time: 0.0148  last_data_time: 0.0124   lr: 6.9681e-05  max_mem: 1546M\n",
            "[05/07 11:25:14 d2.utils.events]:  eta: 0:01:58  iter: 159  total_loss: 1.48  loss_cls: 0.384  loss_box_reg: 0.7655  loss_rpn_cls: 0.1863  loss_rpn_loc: 0.07163    time: 0.3724  last_time: 0.3426  data_time: 0.0116  last_data_time: 0.0133   lr: 7.9671e-05  max_mem: 1546M\n",
            "[05/07 11:25:23 d2.utils.events]:  eta: 0:01:52  iter: 179  total_loss: 1.263  loss_cls: 0.3269  loss_box_reg: 0.7282  loss_rpn_cls: 0.123  loss_rpn_loc: 0.07458    time: 0.3762  last_time: 0.3142  data_time: 0.0122  last_data_time: 0.0034   lr: 8.966e-05  max_mem: 1546M\n",
            "[05/07 11:25:30 d2.utils.events]:  eta: 0:01:46  iter: 199  total_loss: 1.311  loss_cls: 0.3172  loss_box_reg: 0.7441  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.05062    time: 0.3780  last_time: 0.4407  data_time: 0.0130  last_data_time: 0.0169   lr: 9.9651e-05  max_mem: 1546M\n",
            "[05/07 11:25:38 d2.utils.events]:  eta: 0:01:39  iter: 219  total_loss: 1.407  loss_cls: 0.2852  loss_box_reg: 0.8808  loss_rpn_cls: 0.1371  loss_rpn_loc: 0.104    time: 0.3770  last_time: 0.3518  data_time: 0.0115  last_data_time: 0.0052   lr: 0.00010964  max_mem: 1546M\n",
            "[05/07 11:25:46 d2.utils.events]:  eta: 0:01:33  iter: 239  total_loss: 1.337  loss_cls: 0.2972  loss_box_reg: 0.8071  loss_rpn_cls: 0.1457  loss_rpn_loc: 0.1012    time: 0.3805  last_time: 0.4583  data_time: 0.0130  last_data_time: 0.0011   lr: 0.00011963  max_mem: 1546M\n",
            "[05/07 11:25:54 d2.utils.events]:  eta: 0:01:27  iter: 259  total_loss: 1.262  loss_cls: 0.2797  loss_box_reg: 0.7049  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.06503    time: 0.3823  last_time: 0.4326  data_time: 0.0140  last_data_time: 0.0065   lr: 0.00012962  max_mem: 1546M\n",
            "[05/07 11:26:03 d2.utils.events]:  eta: 0:01:20  iter: 279  total_loss: 1.339  loss_cls: 0.3361  loss_box_reg: 0.8442  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.08565    time: 0.3850  last_time: 0.4250  data_time: 0.0136  last_data_time: 0.0159   lr: 0.00013961  max_mem: 1546M\n",
            "[05/07 11:26:11 d2.utils.events]:  eta: 0:01:13  iter: 299  total_loss: 1.217  loss_cls: 0.2333  loss_box_reg: 0.7824  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.08199    time: 0.3856  last_time: 0.5427  data_time: 0.0117  last_data_time: 0.0258   lr: 0.0001496  max_mem: 1546M\n",
            "[05/07 11:26:18 d2.utils.events]:  eta: 0:01:05  iter: 319  total_loss: 1.213  loss_cls: 0.2244  loss_box_reg: 0.8057  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.1028    time: 0.3857  last_time: 0.4279  data_time: 0.0137  last_data_time: 0.0088   lr: 0.00015959  max_mem: 1546M\n",
            "[05/07 11:26:27 d2.utils.events]:  eta: 0:00:59  iter: 339  total_loss: 1.175  loss_cls: 0.231  loss_box_reg: 0.7537  loss_rpn_cls: 0.09574  loss_rpn_loc: 0.04086    time: 0.3877  last_time: 0.3825  data_time: 0.0155  last_data_time: 0.0279   lr: 0.00016958  max_mem: 1546M\n",
            "[05/07 11:26:34 d2.utils.events]:  eta: 0:00:51  iter: 359  total_loss: 1.143  loss_cls: 0.1885  loss_box_reg: 0.689  loss_rpn_cls: 0.08146  loss_rpn_loc: 0.06491    time: 0.3866  last_time: 0.3626  data_time: 0.0093  last_data_time: 0.0061   lr: 0.00017957  max_mem: 1546M\n",
            "[05/07 11:26:42 d2.utils.events]:  eta: 0:00:44  iter: 379  total_loss: 1.194  loss_cls: 0.2091  loss_box_reg: 0.754  loss_rpn_cls: 0.09938  loss_rpn_loc: 0.05448    time: 0.3874  last_time: 0.4629  data_time: 0.0112  last_data_time: 0.0160   lr: 0.00018956  max_mem: 1546M\n",
            "[05/07 11:26:50 d2.utils.events]:  eta: 0:00:37  iter: 399  total_loss: 1.162  loss_cls: 0.2671  loss_box_reg: 0.6543  loss_rpn_cls: 0.08331  loss_rpn_loc: 0.09834    time: 0.3870  last_time: 0.3361  data_time: 0.0118  last_data_time: 0.0131   lr: 0.00019955  max_mem: 1546M\n",
            "[05/07 11:26:58 d2.utils.events]:  eta: 0:00:29  iter: 419  total_loss: 1.045  loss_cls: 0.2029  loss_box_reg: 0.6977  loss_rpn_cls: 0.07071  loss_rpn_loc: 0.05063    time: 0.3882  last_time: 0.3807  data_time: 0.0142  last_data_time: 0.0093   lr: 0.00020954  max_mem: 1546M\n",
            "[05/07 11:27:06 d2.utils.events]:  eta: 0:00:22  iter: 439  total_loss: 1.078  loss_cls: 0.1974  loss_box_reg: 0.7113  loss_rpn_cls: 0.09662  loss_rpn_loc: 0.06047    time: 0.3879  last_time: 0.4795  data_time: 0.0126  last_data_time: 0.0314   lr: 0.00021953  max_mem: 1546M\n",
            "[05/07 11:27:14 d2.utils.events]:  eta: 0:00:14  iter: 459  total_loss: 1.014  loss_cls: 0.1731  loss_box_reg: 0.7148  loss_rpn_cls: 0.06841  loss_rpn_loc: 0.07514    time: 0.3884  last_time: 0.4140  data_time: 0.0151  last_data_time: 0.0897   lr: 0.00022952  max_mem: 1546M\n",
            "[05/07 11:27:22 d2.utils.events]:  eta: 0:00:07  iter: 479  total_loss: 1.045  loss_cls: 0.1675  loss_box_reg: 0.675  loss_rpn_cls: 0.08169  loss_rpn_loc: 0.05402    time: 0.3895  last_time: 0.4798  data_time: 0.0132  last_data_time: 0.0349   lr: 0.00023951  max_mem: 1546M\n",
            "[05/07 11:27:32 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.9831  loss_cls: 0.161  loss_box_reg: 0.6501  loss_rpn_cls: 0.07689  loss_rpn_loc: 0.05981    time: 0.3884  last_time: 0.3518  data_time: 0.0114  last_data_time: 0.0035   lr: 0.0002495  max_mem: 1546M\n",
            "[05/07 11:27:33 d2.engine.hooks]: Overall training speed: 498 iterations in 0:03:13 (0.3884 s / it)\n",
            "[05/07 11:27:33 d2.engine.hooks]: Total training time: 0:03:20 (0:00:07 on hooks)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "# Load the custom dataset\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"my_dataset_train\", {},train_json_path, '/content/dataset_1/COCO_Dataset/train/images')\n",
        "\n",
        "# Configure the model parameters\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # Increase this number based on your GPU memory\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 500\n",
        "cfg.SOLVER.STEPS = []  # No LR steps, you can add steps if you want LR decay\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 16\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Change this to the number of classes in your dataset\n",
        "cfg.OUTPUT_DIR = \"./output_directory\"  # Change this to the desired output directory\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Create and train the model\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model is trained now we are testing our trained model"
      ],
      "metadata": {
        "id": "vdJA1ZetCfzc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo-5mnLppGol",
        "outputId": "45024609-8196-4222-9516-c9479755d79a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/07 11:28:39 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from ./output_directory/model_final.pth ...\n"
          ]
        }
      ],
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKQMMzjs0Sl7"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # Assuming you are using Google Colab\n",
        "\n",
        "# Load the dataset dictionaries for the validation dataset\n",
        "dataset_dicts = load_dataset_from_json(valid_json_path)\n",
        "\n",
        "# Randomly sample 3 images from the dataset for visualization\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    # Print the dictionary (commented out, can be useful for debugging)\n",
        "    # print(d)\n",
        "\n",
        "    # Read the image file\n",
        "    im = cv2.imread('/content/dataset_1/COCO_Dataset/valid/images/' + d[\"file_name\"])\n",
        "\n",
        "    # Print the image (commented out, can be useful for debugging)\n",
        "    # print(im)\n",
        "\n",
        "    # Perform inference on the image using the predictor\n",
        "    outputs = predictor(im)  # The format of outputs is documented in Detectron2 documentation\n",
        "\n",
        "    # Create a Visualizer object to visualize the image and predictions\n",
        "    v = Visualizer(im[:, :, ::-1],  # Convert BGR to RGB\n",
        "                   metadata=metadata_val,\n",
        "                   scale=0.5,\n",
        "                   instance_mode=ColorMode.IMAGE_BW  # Grayscale unsegmented areas (for segmentation models)\n",
        "    )\n",
        "\n",
        "    # Draw the instance predictions on the image\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    # Display the image with predictions (converting RGB back to BGR for display)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}